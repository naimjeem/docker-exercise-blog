name: Build & Deploy Pipeline

on:
  workflow_run:
    workflows: ["Quality Gates Pipeline"]
    types: [completed]
    branches: [main]
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  PERFORMANCE_THRESHOLD_MS: 200

jobs:
  # Job 1: Build & Containerization
  build:
    name: Build & Push Container
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    outputs:
      image-digest: ${{ steps.build.outputs.digest }}
      image-tag: ${{ steps.meta.outputs.tags }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker-compose.yml
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # Job 2: Performance Testing
  performance-test:
    name: Performance Testing
    runs-on: ubuntu-latest
    needs: build
    outputs:
      performance-passed: ${{ steps.performance-check.outputs.passed }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Start application stack
        run: |
          docker-compose up -d
          sleep 30

      - name: Wait for services to be ready
        run: |
          timeout 60 bash -c 'until curl -f http://localhost:5000/health; do sleep 2; done'

      - name: Install k6
        run: |
          sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Create performance test script
        run: |
          cat > performance-test.js << 'EOF'
          import http from 'k6/http';
          import { check, sleep } from 'k6';
          import { Rate } from 'k6/metrics';
          
          const errorRate = new Rate('errors');
          
          export const options = {
            stages: [
              { duration: '30s', target: 10 },
              { duration: '1m', target: 10 },
              { duration: '30s', target: 0 },
            ],
            thresholds: {
              http_req_duration: ['p(95)<200'],
              errors: ['rate<0.1'],
            },
          };
          
          export default function () {
            const responses = http.batch([
              ['GET', 'http://localhost:5000/health'],
              ['GET', 'http://localhost:5000/api/posts'],
            ]);
          
            responses.forEach(response => {
              check(response, {
                'status is 200': (r) => r.status === 200,
                'response time < 200ms': (r) => r.timings.duration < 200,
              });
              errorRate.add(response.status !== 200);
            });
          
            sleep(1);
          }
          EOF

      - name: Run performance tests
        run: |
          k6 run --out json=performance-results.json performance-test.js

      - name: Check performance results
        id: performance-check
        run: |
          if [ -f performance-results.json ]; then
            P95_TIME=$(jq -r '.metrics.http_req_duration.values.p95' performance-results.json)
            echo "P95 Response Time: ${P95_TIME}ms"
            
            if (( $(echo "$P95_TIME > ${{ env.PERFORMANCE_THRESHOLD_MS }}" | bc -l) )); then
              echo "âŒ P95 response time ${P95_TIME}ms exceeds threshold ${{ env.PERFORMANCE_THRESHOLD_MS }}ms"
              echo "passed=false" >> $GITHUB_OUTPUT
              exit 1
            fi
            
            echo "âœ… Performance threshold met"
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "âŒ Performance test results not found"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-results
          path: performance-results.json

      - name: Cleanup
        if: always()
        run: docker-compose down

  # Job 3: Container Security Scanning
  container-scan:
    name: Container Security Scan
    runs-on: ubuntu-latest
    needs: build
    outputs:
      security-passed: ${{ steps.security-check.outputs.passed }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ needs.build.outputs.image-tag }}
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Check for HIGH/CRITICAL vulnerabilities
        id: security-check
        run: |
          # Run Trivy with JSON output for parsing
          docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
            aquasec/trivy image --format json --output trivy-results.json \
            ${{ needs.build.outputs.image-tag }}
          
          # Check for HIGH and CRITICAL vulnerabilities
          HIGH_VULNS=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "HIGH")] | length' trivy-results.json)
          CRITICAL_VULNS=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "CRITICAL")] | length' trivy-results.json)
          
          echo "HIGH severity vulnerabilities: $HIGH_VULNS"
          echo "CRITICAL severity vulnerabilities: $CRITICAL_VULNS"
          
          if [ "$HIGH_VULNS" -gt 0 ] || [ "$CRITICAL_VULNS" -gt 0 ]; then
            echo "âŒ HIGH or CRITICAL vulnerabilities found"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "âœ… No HIGH or CRITICAL vulnerabilities found"
          echo "passed=true" >> $GITHUB_OUTPUT

      - name: Upload security scan results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-scan-results
          path: |
            trivy-results.sarif
            trivy-results.json

  # Job 4: Deploy to Staging
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [build, performance-test, container-scan]
    if: |
      needs.build.result == 'success' &&
      needs.performance-test.outputs.performance-passed == 'true' &&
      needs.container-scan.outputs.security-passed == 'true'
    environment:
      name: staging
      url: https://staging-blog.example.com
    outputs:
      staging-url: ${{ steps.deploy.outputs.url }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Deploy to staging
        id: deploy
        run: |
          echo "ðŸš€ Deploying to staging environment..."
          # Simulate deployment - replace with actual deployment logic
          echo "url=https://staging-blog.example.com" >> $GITHUB_OUTPUT
          echo "âœ… Staging deployment completed"

      - name: Wait for deployment to be ready
        run: |
          echo "â³ Waiting for staging deployment to be ready..."
          sleep 30

  # Job 5: Smoke Tests
  staging-smoke-tests:
    name: Staging Smoke Tests
    runs-on: ubuntu-latest
    needs: deploy-staging
    outputs:
      smoke-tests-passed: ${{ steps.smoke-check.outputs.passed }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run smoke tests
        run: |
          STAGING_URL="${{ needs.deploy-staging.outputs.staging-url }}"
          
          echo "ðŸ§ª Running smoke tests against $STAGING_URL"
          
          # Test 1: Health endpoint
          echo "Testing health endpoint..."
          HEALTH_RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" "$STAGING_URL/health")
          if [ "$HEALTH_RESPONSE" != "200" ]; then
            echo "âŒ Health endpoint failed: $HEALTH_RESPONSE"
            exit 1
          fi
          echo "âœ… Health endpoint OK"
          
          # Test 2: Posts endpoint
          echo "Testing posts endpoint..."
          POSTS_RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" "$STAGING_URL/api/posts")
          if [ "$POSTS_RESPONSE" != "200" ]; then
            echo "âŒ Posts endpoint failed: $POSTS_RESPONSE"
            exit 1
          fi
          echo "âœ… Posts endpoint OK"
          
          # Test 3: Create post
          echo "Testing post creation..."
          CREATE_RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" \
            -X POST "$STAGING_URL/api/posts" \
            -H "Content-Type: application/json" \
            -d '{"title":"Smoke Test Post","content":"This is a smoke test","author":"CI/CD"}')
          if [ "$CREATE_RESPONSE" != "201" ]; then
            echo "âŒ Post creation failed: $CREATE_RESPONSE"
            exit 1
          fi
          echo "âœ… Post creation OK"

      - name: Check smoke test results
        id: smoke-check
        run: |
          echo "âœ… All smoke tests passed"
          echo "passed=true" >> $GITHUB_OUTPUT

  # Job 6: Deploy to Production
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: staging-smoke-tests
    if: needs.staging-smoke-tests.outputs.smoke-tests-passed == 'true'
    environment:
      name: production
      url: https://blog.example.com
    outputs:
      production-url: ${{ steps.deploy.outputs.url }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Deploy to production
        id: deploy
        run: |
          echo "ðŸš€ Deploying to production environment..."
          # Simulate deployment - replace with actual deployment logic
          echo "url=https://blog.example.com" >> $GITHUB_OUTPUT
          echo "âœ… Production deployment completed"

      - name: Wait for deployment to be ready
        run: |
          echo "â³ Waiting for production deployment to be ready..."
          sleep 30

  # Job 7: Post-Deployment Verification
  post-deployment-verification:
    name: Post-Deployment Verification
    runs-on: ubuntu-latest
    needs: deploy-production
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run post-deployment tests
        run: |
          PRODUCTION_URL="${{ needs.deploy-production.outputs.production-url }}"
          
          echo "ðŸ” Running post-deployment verification against $PRODUCTION_URL"
          
          # Test critical endpoints
          curl -f "$PRODUCTION_URL/health" || (echo "âŒ Health check failed" && exit 1)
          curl -f "$PRODUCTION_URL/api/posts" || (echo "âŒ Posts endpoint failed" && exit 1)
          
          echo "âœ… Post-deployment verification passed"

      - name: Rollback on failure
        if: failure()
        run: |
          echo "ðŸš¨ Post-deployment verification failed - initiating rollback"
          # Implement rollback logic here
          echo "ðŸ”„ Rolling back to previous version..."
          # This would typically involve:
          # 1. Reverting to previous container image
          # 2. Updating load balancer configuration
          # 3. Notifying team of rollback
          echo "âœ… Rollback completed"

  # Job 8: Notify Results
  notify:
    name: Notify Build & Deploy Results
    runs-on: ubuntu-latest
    needs: [build, performance-test, container-scan, staging-smoke-tests, deploy-production, post-deployment-verification]
    if: always()
    steps:
      - name: Determine pipeline status
        id: status
        run: |
          if [ "${{ needs.post-deployment-verification.result }}" == "success" ]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "message=âœ… Build & Deploy pipeline completed successfully" >> $GITHUB_OUTPUT
          elif [ "${{ needs.post-deployment-verification.result }}" == "failure" ]; then
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "message=âŒ Build & Deploy pipeline failed - Rollback initiated" >> $GITHUB_OUTPUT
          else
            echo "status=cancelled" >> $GITHUB_OUTPUT
            echo "message=âš ï¸ Build & Deploy pipeline was cancelled" >> $GITHUB_OUTPUT
          fi

      - name: Create build & deploy summary
        run: |
          echo "## ðŸš€ Build & Deploy Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Status:** ${{ steps.status.outputs.status }}" >> $GITHUB_STEP_SUMMARY
          echo "**Message:** ${{ steps.status.outputs.message }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Pipeline Results:" >> $GITHUB_STEP_SUMMARY
          echo "- Build & Push: ${{ needs.build.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Performance Test: ${{ needs.performance-test.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Security Scan: ${{ needs.container-scan.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Smoke Tests: ${{ needs.staging-smoke-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Production Deploy: ${{ needs.deploy-production.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Post-Deploy Verification: ${{ needs.post-deployment-verification.result }}" >> $GITHUB_STEP_SUMMARY
